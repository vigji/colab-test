{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading packages and functions\n",
    "\n",
    "**Understand what the packages below are and do.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-photon dataset\n",
    "**Load the tiff stack corresponding to plane 65: *plane065.tif* and load it into a numpy array called *images*. A stack is a file that contains a set of images. It is therefore a three dimensional array (Z,X,Y) or (T,X,Y) depending on whether the different images are from different planes or the same plane at different times. You can also open this stack with ImageJ and browse through it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open(r\"C:\\Users\\rportugues\\zenith\\2p\\plane065.tif\")\n",
    "images = []\n",
    "for i in range(img.n_frames):\n",
    "    img.seek(i)\n",
    "    images.append(np.array(img))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use np.shape to query the dimensions of the array *images*. Does this make sense from what you observed in ImageJ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1750, 400, 414)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate an anatomy of this plane by summing all the frames. It should look very similar to**\n",
    "\n",
    "![](images/figure1.png)\n",
    "\n",
    "**Do you know where you are in the fish brain?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "122217e8f89f46028fc09f4efc41eb9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f2452f54c8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_anatomy=np.sum(images,0)\n",
    "plt.figure()\n",
    "plt.imshow(original_anatomy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we will use the function** phase_cross_correlation **from skimage. We want to perform sub-pixel corrections, say to 0.1 of a pixel, so make sure you use the** upsample_factor **argument. Save the shifts in the X and Y directions in two arrays called *Xs* and *Ys* and compute also a *total_motion* array (use pythagoras).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.registration import phase_cross_correlation\n",
    "import math\n",
    "frames=np.array(images)\n",
    "Xs=np.zeros(np.shape(images)[0])\n",
    "Ys=np.zeros(np.shape(images)[0])\n",
    "total_motion=np.zeros(np.shape(images)[0])\n",
    "for i in range(frames.shape[0]):\n",
    "    X=phase_cross_correlation(original_anatomy, frames[i,:,:] ,upsample_factor=10, space='real')\n",
    "    Xs[i]=X[0][0]\n",
    "    Ys[i]=X[0][1]\n",
    "    total_motion[i]=math.sqrt(Xs[i]*Xs[i]+Ys[i]*Ys[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the total motion of each frame. Do you think the motion arises from continuous drifts or acute motor events? In a second subplot, plot a scatter plot of the shift for each frame. You can choose to add some jitter so you can visualize dots that are superimposed on one another.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ed08373de44c1eb7a8f3674616e6a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(total_motion)\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(Xs-0.01+0.02*np.random.rand(Xs.shape[0]),Ys-0.01+0.02*np.random.rand(Xs.shape[0]),s=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second order correction of motion artifact\n",
    "\n",
    "**Correct the individual frames by performing an individual sub-pixel alignment frame by frame. In order to do this use the function** shift **from** scipy.image.\n",
    "\n",
    "**Use this new corrected stack to generate a new aligned_anatomy. Display the difference image between the original and the aligned anatomies.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import shift\n",
    "aligned_frames=np.zeros(frames.shape)\n",
    "for i in range(frames.shape[0]):\n",
    "    aligned_frames[i,:,:]=shift(frames[i,:,:], (Xs[i],Ys[i]), output=None, order=3, mode='constant', cval=0.0, prefilter=True)\n",
    "#   the commented lines below check that the shift was performed in the correct direction    \n",
    "#   X=phase_cross_correlation(anatomy, frames[i,:,:] ,upsample_factor=10, space='real')\n",
    "#   print(X)\n",
    "#   Y=phase_cross_correlation(anatomy, aligned_frames[i,:,:] ,upsample_factor=10, space='real')\n",
    "#   print(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "756b88ae504746e9b73fbc47bbba3e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f313d1dc48>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligned_anatomy=np.sum(aligned_frames,0)\n",
    "plt.figure()\n",
    "plt.imshow(original_anatomy-aligned_anatomy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Align the ORIGINAL frames to this new aligned_anatomy. Compute the total shift of each frame to this aligned_anatomy and plot this shift on top of the shift you obtained for the first alignment. Why are these different?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.registration import phase_cross_correlation\n",
    "import math\n",
    "Xs2=np.zeros(np.shape(images)[0])\n",
    "Ys2=np.zeros(np.shape(images)[0])\n",
    "total_motion2=np.zeros(np.shape(images)[0])\n",
    "for i in range(frames.shape[0]):\n",
    "    X=phase_cross_correlation(aligned_anatomy, frames[i,:,:] ,upsample_factor=10, space='real')\n",
    "    Xs2[i]=X[0][0]\n",
    "    Ys2[i]=X[0][1]\n",
    "    total_motion2[i]=math.sqrt(Xs2[i]*Xs2[i]+Ys2[i]*Ys2[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb39bdcd1c9453db9f851c5b397ec92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(total_motion)\n",
    "plt.plot(total_motion2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally shift the original frames by this new amount to obtain a final stack. You can sum this final stack to obtain a final anatomy.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import shift\n",
    "final_frames=np.zeros(frames.shape)\n",
    "for i in range(frames.shape[0]):\n",
    "    final_frames[i,:,:]=shift(frames[i,:,:], (Xs2[i],Ys2[i]), output=None, order=3, mode='constant', cval=0.0, prefilter=True)\n",
    "final_anatomy=np.sum(final_frames,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a43f87a1e3cf4e8b99ff4505f4ce69c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f313df11c8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(original_anatomy)\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(aligned_anatomy)\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(final_anatomy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a correlation map\n",
    "\n",
    "**Use the function** pearsonr **from** scipy.stats **to compute the correlation between the fluorescence time series of one pixel and the fluorescence time series of its eight surrounding pixels summed (ignore boundary pixels for now).**\n",
    "\n",
    "**Plot it alongside the anatomy. It should look something like:**\n",
    "\n",
    "![](images/figure2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "correlation_map=np.zeros(final_anatomy.shape)\n",
    "for i in range(final_anatomy.shape[0]):\n",
    "    if i>0 and i<(final_anatomy.shape[0]-1):\n",
    "        for j in range(final_anatomy.shape[1]):\n",
    "            if j>0 and j<(final_anatomy.shape[1]-1):\n",
    "                this_pixel=np.squeeze(final_frames[:,i,j])\n",
    "                surr_pixels=np.squeeze(np.sum(np.sum(np.squeeze(final_frames[:,i-1:i+1,j-1:j+1]),2),1))-this_pixel\n",
    "                C, _ = pearsonr(this_pixel, surr_pixels)\n",
    "                correlation_map[i,j]=C\n",
    "original_correlation_map=np.copy(correlation_map)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a45447e7b0b04f7f87aa75ba61f14350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(final_anatomy)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(correlation_map)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot a histogram of the correlation values. The top left and the bottom left of the image are not within the fish brain. Plot a histogram of the correlation values in this part of the image to gain some insight into the distribution of correlation values of the noise.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROI extraction\n",
    "\n",
    "**We will now generate a function that extracts ROIs (regions of interest). The function should take 4 inputs: a correlation map, the final stack of aligned frames, a correlation threshold value and a maximum size of an ROI in pixels.**\n",
    "\n",
    "**The function should:**\n",
    "- Identify the pixel with the highest correlation value in the correlation map (the ROI seed). Initialize the list of pixels in this ROI with this seed.**\n",
    "- Compute the individual correlations of the fluorescence time-series in this pixel with its 8 neighbours. A convenient way of idetifying the neighbours of a region is by dilating the reion by one piexl. You can do this by importing **morphology** from skimage and using **morphology.binary_dilation**.\n",
    "- Add the neighbours whose correlation exceeds the threshold to the ROI.\n",
    "- Repeat by looking at the neighbouring pixels of the new ROI and computing the correlation of their fluorescence with the total fluorescence of the ROI. Add the pixels to the ROI if they exceed the threshold. \n",
    "- Stop the function if no neighbouring pixels exceed the threshold or if the size of the ROI exceeds the maximum size (the last input to the function).\n",
    "- The function should return the pixels within the ROI, the fluoresence trace of the ROI, the size of the ROI and the correlation map with the values of the pixels in the extracted ROI set to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_map=np.copy(original_correlation_map)\n",
    "\n",
    "def next_roi(Vcorrelation_map, Vframes, corr_thresh, Vsize):\n",
    "    \n",
    "    this_max=np.max(Vcorrelation_map)\n",
    "    #print(this_max)\n",
    "    result = np.where(Vcorrelation_map== this_max)\n",
    "    coords=list(zip(result[0], result[1]))\n",
    "    I=coords[0][0]\n",
    "    J=coords[0][1]\n",
    "    this_roi_trace=np.squeeze(Vframes[:,I,J])\n",
    "    this_roi=np.zeros(Vcorrelation_map.shape)\n",
    "    this_roi[I,J]=1;\n",
    "    this_correlation_map=np.copy(Vcorrelation_map)\n",
    "    this_correlation_map[I,J]=0;\n",
    "    from skimage import morphology\n",
    "\n",
    "    added=1\n",
    "    while (np.sum(np.sum(this_roi,1),0)<Vsize and added==1):\n",
    "        added=0\n",
    "        dilated=morphology.binary_dilation(this_roi, np.ones((3,3))).astype(np.uint8)\n",
    "        new_pixels=dilated-this_roi\n",
    "        result = np.where(new_pixels == 1)\n",
    "        coords=list(zip(result[0], result[1]))\n",
    "        coords2=np.asarray(coords, dtype=np.int32)\n",
    "        for a in range(coords2.shape[0]):\n",
    "            I=coords2[a][0]\n",
    "            J=coords2[a][1]\n",
    "            if not(this_correlation_map[I,J]==0):\n",
    "                Y=np.squeeze(Vframes[:,I,J])\n",
    "                C, _ = pearsonr(this_roi_trace, Y)\n",
    "                if C>corr_thresh:\n",
    "                    this_roi[I,J]=1\n",
    "                    this_correlation_map[I,J]=0\n",
    "                    this_roi_trace=this_roi_trace+Y\n",
    "                    added=1\n",
    "\n",
    "    return this_roi, this_roi_trace, np.sum(np.sum(this_roi,1),0), this_correlation_map\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use the function you have written to extract 200 ROIs within the plane. Use a correlation threshold value of 0.8 and a maximum ROI size of 200 pixels.**\n",
    "\n",
    "**Plot a figure with three subplots. The first one should be an image of the fluorescence of the 200 ROIs. Make sure that you plot the normalized or zscored fluorescence for each ROI to be able to compare them. Import** zscore **from** scipy.stats **to do this. The second one a map showing the ROIs extraces and the thirs one the original correlation map with the correlation of the extracted ROIs set to zero. It should look something like this:**\n",
    "\n",
    "![](images/figure3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nrois=200\n",
    "all_traces=np.zeros((Nrois,aligned_frames.shape[0]))\n",
    "all_rois=np.zeros(original_correlation_map.shape)\n",
    "used_pixels=np.zeros(original_correlation_map.shape)\n",
    "\n",
    "for i in range(Nrois):\n",
    "    this_roi3,this_roi_trace,N,this_correlation_map=next_roi(correlation_map, aligned_frames, 0.8,200)\n",
    "    all_traces[i,:]=this_roi_trace\n",
    "    all_rois=all_rois+(i+1)*this_roi3\n",
    "    used_pixels=used_pixels+this_roi3\n",
    "    correlation_map[all_rois>0]=0\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2f70caa1f474a8399b639ff54c91029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "fig,(ax1,ax2,ax3)= plt.subplots(1,3)\n",
    "\n",
    "img=ax1.imshow(zscore(all_traces, 1), aspect=\"auto\", vmin=-3, vmax=3, cmap=\"RdBu_r\")\n",
    "ax1.set_ylabel(\"trace ROI number\")\n",
    "ax1.set_xlabel(\"frame number\")\n",
    "fig.colorbar(img,ax=ax1)\n",
    "ax2.imshow(all_rois)\n",
    "ax3.imshow(correlation_map)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the array with the traces as a numpy data file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"traces.npy\", all_traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_traces=np.load(\"traces.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "expt_time = pd.read_csv(r\"C:\\Users\\rportugues\\zenith\\2p\\time.csv\")\n",
    "coherences = pd.read_csv(r\"C:\\Users\\rportugues\\zenith\\2p\\stimulus.csv\")\n",
    "behavior = pd.read_csv(r\"C:\\Users\\rportugues\\zenith\\2p\\behavior.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23806c6664b6431d97f03a97c81ef4d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f313d6ffc8>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stimulus=coherences[\"Coherence\"]\n",
    "stimulus=np.array(stimulus)\n",
    "stimulus[stimulus<-5]=0\n",
    "\n",
    "time=expt_time[\"Time\"]\n",
    "time=np.array(time)\n",
    "\n",
    "beh_65=behavior[\"Plane65\"]\n",
    "beh_65=np.array(beh_65/np.max(np.absolute(beh_65)))\n",
    "beh_65[np.argwhere(np.isnan(beh_65))]=0\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(time,stimulus)\n",
    "plt.plot(time,beh_65-0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6b578adeb2743bbb41c3fd23e969a99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "exp_t=np.zeros((2000))\n",
    "exp_k=np.zeros((2000))\n",
    "for i in range(2000):\n",
    "    exp_t[i]=10*i-10000\n",
    "    exp_k[i]=math.exp(-(10*i-10000)/1500)\n",
    "exp_k[exp_t<0]=0\n",
    "plt.figure()\n",
    "plt.plot(exp_t,exp_k)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bf3e2ce33094e009e315ba9f2c052ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vig=beh_65*beh_65\n",
    "plt.figure()\n",
    "plt.plot(time,vig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we define motor regressors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff644116cb4c48818a1635d13ed38dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_regressors=4\n",
    "Reg=np.empty((4,vig.shape[0]))\n",
    "\n",
    "Reg[0,:]=np.convolve(vig,exp_k,'same')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(time,Reg[0,:])\n",
    "plt.plot(time,beh_65-0.5)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we define stimulus regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66516cf975948428bdf52c3a06bb29b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stimulus[np.argwhere(np.isnan(stimulus))]=0\n",
    "stimulusP=np.copy(stimulus)\n",
    "stimulusP[stimulusP<0]=0;\n",
    "stimulusN=np.copy(stimulus)\n",
    "stimulusN[stimulusN>0]=0;\n",
    "stimulusN=-stimulusN\n",
    "\n",
    "Reg[1,:]=np.convolve(stimulus,exp_k,'same')\n",
    "Reg[2,:]=np.convolve(stimulusP,exp_k,'same')\n",
    "Reg[3,:]=np.convolve(stimulusN,exp_k,'same')\n",
    "\n",
    "plt.figure()\n",
    "for j in range(0,4):\n",
    "    plt.plot(time,Reg[j,:]-10*j)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 0.00000000e+00, 1.61782092e-06, ...,\n",
       "       3.67897152e-03, 3.68579446e-03, 3.67382042e-03])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Reg[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging_times=np.zeros(1736);\n",
    "for i in range(1736):\n",
    "    imaging_times[i]=i*334;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_regressors=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There are 1750 imaging frames, taken every 334 ms. The behavior was recorded until time 580s, which corresponds to the time of the 1736.5 imaging frame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8e5d4a19fff48e88ce3ea473c4966c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "int_Reg=np.zeros([num_regressors,1736])\n",
    "from scipy import interpolate\n",
    "\n",
    "plt.figure()\n",
    "for j in range(num_regressors):\n",
    "    f=interpolate.interp1d(time,Reg[j,:])\n",
    "    int_Reg[j,:]=f(imaging_times)\n",
    "    int_Reg[j,:]=int_Reg[j,:]/(np.max(np.abs(int_Reg[j,:])))\n",
    "    plt.plot(imaging_times,int_Reg[j,:]-j)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We compute the correlation of each ROI with each of the rgressors we have defined and we save these values into a matrix called all_correlations(num_regressors,number_ROIs)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "all_correlations=np.zeros([num_regressors,200])\n",
    "for k in range(num_regressors):\n",
    "    for j in range(200):\n",
    "        C,_=pearsonr(int_Reg[k,:],all_traces[j,0:1736])\n",
    "        all_correlations[k,j]=C\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11454b593ebc47679713589bccdc52b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(np.transpose(all_correlations))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can now plot the ROI that has the highest correlation with each of the four regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82ff95582f19464db341589030b79a5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "for k in range(4):\n",
    "    id=np.argmax(all_correlations[k,:])\n",
    "    Y=all_traces[id,0:1736]\n",
    "    Y=Y-np.min(Y)\n",
    "    Y=Y/np.max(Y)\n",
    "    plt.plot(imaging_times,Y-1.5*k)\n",
    "    plt.plot(imaging_times,int_Reg[k,:]-1.5*k)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ... and the ROI that has the lowest correlation with each of the four regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e51d78f3c6e4d119a5b0c08d85ec812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "for k in range(4):\n",
    "    id=np.argmin(all_correlations[k,:])\n",
    "    Y=all_traces[id,0:1736]\n",
    "    Y=Y-np.min(Y)\n",
    "    Y=Y/np.max(Y)\n",
    "    plt.plot(imaging_times,Y-1.5*k)\n",
    "    plt.plot(imaging_times,int_Reg[k,:]-1.5*k)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Population Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis\n",
    "\n",
    "Let us start by doing some principal component analysis to investigate the activity traces that describe most of the variance. We can start asking for the first 10 principal components (PCs). We feed the normalized fluorescence traces. We also plot the variance explained by each principal component. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import zscore\n",
    "\n",
    "pca=PCA(n_components=10)\n",
    "principalComponents=pca.fit_transform(zscore(all_traces,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.40869205, 0.1137854 , 0.09299108, 0.04841201, 0.03935416,\n",
       "       0.02709126, 0.02300525, 0.02076977, 0.01920987, 0.01505074])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c7b916f6d6442583597a6a356a532d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "for i in range(10):\n",
    "    plt.plot(pca.components_[i]-0.1*i)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53d9ebe667a43fb8545ddcb77db09a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure()\n",
    "ax=plt.axes(projection='3d')\n",
    "ax.scatter(principalComponents[:,0],principalComponents[:,1],principalComponents[:,2])\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Exercise\n",
    "\n",
    "**Cluster the normalized fluorescence traces into clusters using k-means. Try between 2 and 10 clusters. For each number of clusters, plot the total remaining unexplained variance (the sum of the distances squared between each point and its cluster centroid. How many clusters do you think there are?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now cluster the correlation values into clusters using k-means. Again, try between 2 and 10 clusters. For each number of clusters, plot the total remaining unexplained variance (the sum of the distances squared between each point and its cluster centroid. How many clusters do you think there are? Do the clusters computer in two different ways above agree?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We now cluster using the first 10 PC coefficients. Just as an example we cluster into 3 and 6 clusters.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb62e3dcb4340a4ab9b5f83202440b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "distances=np.zeros((10,1))\n",
    "\n",
    "for j in range(2,10,1):\n",
    "  kmeans=KMeans(j,n_init=30).fit(principalComponents[:,0:9])\n",
    "  Y=kmeans.labels_\n",
    "  distances[j]=kmeans.inertia_\n",
    "\n",
    "fig=plt.figure()\n",
    "plt.subplot(131)\n",
    "plt.plot(np.asarray(range(2,10,1)),distances[2:10])\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Sum of the square distances from points to cluster centers')\n",
    "\n",
    "kmeans=KMeans(3,n_init=30).fit(principalComponents[:,0:9])\n",
    "Y=kmeans.labels_\n",
    "Y3=Y\n",
    "Z3=kmeans.cluster_centers_\n",
    "\n",
    "plt.subplot(132)\n",
    "for i in range(3):\n",
    "  X=principalComponents[:,0:9]\n",
    "  K=X[np.squeeze(Y==i),:]\n",
    "  if i==0:\n",
    "    plt.scatter(K[:,0],K[:,1],10,'r',alpha=0.5)\n",
    "    plt.scatter(Z3[i,0],Z3[i,1],40,'r',marker='*')\n",
    "  if i==1:\n",
    "    plt.scatter(K[:,0],K[:,1],10,'b',alpha=0.5)\n",
    "    plt.scatter(Z3[i,0],Z3[i,1],40,'b',marker='*')\n",
    "  if i==2:\n",
    "    plt.scatter(K[:,0],K[:,1],10,'k',alpha=0.5)\n",
    "    plt.scatter(Z3[i,0],Z3[i,1],40,'k',marker='*')\n",
    "    \n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "\n",
    "kmeans=KMeans(6,n_init=30).fit(principalComponents[:,0:9])\n",
    "Y=kmeans.labels_\n",
    "Z6=kmeans.cluster_centers_\n",
    "Y6=Y\n",
    "Z=Z6\n",
    "\n",
    "plt.subplot(133)\n",
    "for i in range(6):\n",
    "  X=principalComponents[:,0:9]\n",
    "  K=X[np.squeeze(Y==i),:]\n",
    "  if i==0:\n",
    "    plt.scatter(K[:,0],K[:,1],10,'r',alpha=0.5)\n",
    "    plt.scatter(Z[i,0],Z[i,1],40,'r',marker='*')\n",
    "  if i==1:\n",
    "    plt.scatter(K[:,0],K[:,1],10,'b',alpha=0.5)\n",
    "    plt.scatter(Z[i,0],Z[i,1],40,'b',marker='*')\n",
    "  if i==2:\n",
    "    plt.scatter(K[:,0],K[:,1],10,'k',alpha=0.5)\n",
    "    plt.scatter(Z[i,0],Z[i,1],40,'k',marker='*')\n",
    "  if i==3:\n",
    "    plt.scatter(K[:,0],K[:,1],10,'g',alpha=0.5)\n",
    "    plt.scatter(Z[i,0],Z[i,1],40,'g',marker='*')\n",
    "  if i==4:\n",
    "    plt.scatter(K[:,0],K[:,1],10,'c',alpha=0.5)\n",
    "    plt.scatter(Z[i,0],Z[i,1],40,'c',marker='*')\n",
    "  if i==5:\n",
    "    plt.scatter(K[:,0],K[:,1],10,'m',alpha=0.5)\n",
    "    plt.scatter(Z[i,0],Z[i,1],40,'m',marker='*')\n",
    "    \n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd9303422164859b5ced55cc252c2e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,((a0,a1),(a2,a3))=plt.subplots(2,2)\n",
    "ztraces=zscore(all_traces,1)\n",
    "\n",
    "a0.plot(Z3[0,0]*pca.components_[0]+Z3[0,1]*pca.components_[1],'r')\n",
    "a0.plot(Z3[1,0]*pca.components_[0]+Z3[1,1]*pca.components_[1]-3,'b')\n",
    "a0.plot(Z3[2,0]*pca.components_[0]+Z3[2,1]*pca.components_[1]-6,'k')\n",
    "a0.set_ylabel('Activity [norm. fluo.]')\n",
    "a0.set_xlim(0,ztraces.shape[1])\n",
    "\n",
    "a1.plot(Z6[0,0]*pca.components_[0]+Z6[0,1]*pca.components_[1],'r')\n",
    "a1.plot(Z6[1,0]*pca.components_[0]+Z6[1,1]*pca.components_[1]-3,'b')\n",
    "a1.plot(Z6[2,0]*pca.components_[0]+Z6[2,1]*pca.components_[1]-6,'k')\n",
    "a1.plot(Z6[3,0]*pca.components_[0]+Z6[3,1]*pca.components_[1]-9,'g')\n",
    "a1.plot(Z6[4,0]*pca.components_[0]+Z6[4,1]*pca.components_[1]-12,'c')\n",
    "a1.plot(Z6[5,0]*pca.components_[0]+Z6[5,1]*pca.components_[1]-15,'m')\n",
    "a1.set_ylabel('Activity [norm. fluo.]')\n",
    "a1.set_xlim(0,ztraces.shape[1])\n",
    "\n",
    "Zv1=ztraces[Y3==0,:]\n",
    "Zv1b=np.zeros((1,ztraces.shape[1]))\n",
    "Zv2=ztraces[Y3==1,:]\n",
    "Zv3=ztraces[Y3==2,:]\n",
    "\n",
    "traces_stacked=np.concatenate((Zv1,Zv2,Zv3),axis=0)\n",
    "\n",
    "a2.imshow(traces_stacked, aspect=\"auto\", vmin=-3, vmax=3, cmap=\"RdBu_r\")\n",
    "a2.set_xlabel('Time [frames @ 3Hz]')\n",
    "a2.set_ylabel('Relabeled neurons')\n",
    "\n",
    "Zv1=ztraces[Y6==0,:]\n",
    "Zv2=ztraces[Y6==1,:]\n",
    "Zv3=ztraces[Y6==2,:]\n",
    "Zv4=ztraces[Y6==3,:]\n",
    "Zv5=ztraces[Y6==4,:]\n",
    "Zv6=ztraces[Y6==5,:]\n",
    "\n",
    "traces_stacked=np.concatenate((Zv1,Zv2,Zv3,Zv4,Zv5,Zv6),axis=0)\n",
    "\n",
    "a3.imshow(traces_stacked, aspect=\"auto\", vmin=-3, vmax=3, cmap=\"RdBu_r\")\n",
    "a3.set_xlabel('Time [frames @ 3Hz]')\n",
    "a3.set_ylabel('Relabeled neurons')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State space analysis\n",
    "\n",
    "**We now look at how the neurons behave in time. We perform PCA but now we seek the sets of neurons that explain most of the variance, and how these sets of neurons are activated in time.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(n_components=3)\n",
    "principalComponents=pca.fit_transform(np.transpose(zscore(all_traces,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39819508, 0.15238317, 0.08919082])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We color code the trajectories (in time) by the stimulus that was being shown. We plot a 3d scatter plot and 3 2d scatter plots to visualize things well. What are the colors?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3565a06b2dce41c6a0199eaccc6c228f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaf012c0eba445b2900e559de5eb9e79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "col=np.zeros([1750,3])\n",
    "for i in range(1736):\n",
    "    col[i,0]=int_Reg[2,i];\n",
    "    col[i,2]=int_Reg[3,i];\n",
    "    col[i,1]=int_Reg[0,i];\n",
    "    \n",
    "fig2=plt.figure()\n",
    "ax=plt.axes(projection='3d')\n",
    "ax.scatter(principalComponents[:,0],principalComponents[:,1],principalComponents[:,2],c=col[:,:])\n",
    "ax.set_title(\"3d projection\")\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.show()\n",
    "\n",
    "fig,((ax1,ax2,ax3))= plt.subplots(1,3)\n",
    "ax1.scatter(principalComponents[:,0],principalComponents[:,1],c=col[:,:])\n",
    "ax1.set_title(\"PC1 and PC2\")\n",
    "ax2.scatter(principalComponents[:,0],principalComponents[:,2],c=col[:,:])\n",
    "ax2.set_title(\"PC1 and PC2\")\n",
    "ax3.scatter(principalComponents[:,1],principalComponents[:,2],c=col[:,:])\n",
    "ax3.set_title(\"PC1 and PC2\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(n_components=3)\n",
    "principalComponents=pca.fit_transform((zscore(all_traces,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
